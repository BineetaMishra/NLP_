{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk (install the libarry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff models have been pre trained.\n",
    "# for tokenization we call a model where tokenization has already been trained\n",
    "# model name --> 'punkt' model for tokenization.\n",
    "# Model for POS ---->'averaged_perceptron_tagger'\n",
    "# abbrevation used in POS --> guru99.com/pos-tagging-chunking-nltk.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ebineet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# download the trained model \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia.',\n",
       " 'It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "\n",
    "nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6077e5c62728>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "nltk.sent_tokenize(data).dtypes # returns a list datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.sent_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " '(',\n",
       " 'Hindi',\n",
       " ':',\n",
       " 'Bhārat',\n",
       " ')',\n",
       " ',',\n",
       " 'officially',\n",
       " 'the',\n",
       " 'Republic',\n",
       " 'of',\n",
       " 'India',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Bounded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'on',\n",
       " 'the',\n",
       " 'south',\n",
       " ',',\n",
       " 'the',\n",
       " 'Arabian',\n",
       " 'Sea',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southwest',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Bay',\n",
       " 'of',\n",
       " 'Bengal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southeast',\n",
       " ',',\n",
       " 'it',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'Pakistan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'west',\n",
       " ';',\n",
       " 'China',\n",
       " ',',\n",
       " 'Nepal',\n",
       " ',',\n",
       " 'and',\n",
       " 'Bhutan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'north',\n",
       " ';',\n",
       " 'and',\n",
       " 'Bangladesh',\n",
       " 'and',\n",
       " 'Myanmar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " ',',\n",
       " 'India',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vicinity',\n",
       " 'of',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Maldives',\n",
       " ';',\n",
       " 'its',\n",
       " 'Andaman',\n",
       " 'and',\n",
       " 'Nicobar',\n",
       " 'Islands',\n",
       " 'share',\n",
       " 'a',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'with',\n",
       " 'Thailand',\n",
       " 'and',\n",
       " 'Indonesia',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "\n",
    "nltk.word_tokenize(data) # got a list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging  \n",
    " \n",
    " Gramatical tagging\n",
    " \n",
    " Theer are 9 POS\n",
    " \n",
    " Noun--> NN, NNS, NNP, NNps\n",
    " \n",
    " Noun - 4 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization, then send each to POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'we will see an example of POS tagging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st setp ---> Word Tokenization\n",
    "word_token= nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'will', 'see', 'an', 'example', 'of', 'POS', 'tagging']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ebineet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('see', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('example', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('POS', 'NNP'),\n",
       " ('tagging', 'VBG')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd POS\n",
    "# Model for POS\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos = nltk.pos_tag(word_token)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS \n",
    "Abbreviation\tMeaning\n",
    "CC\tcoordinating conjunction <br>\n",
    "CD\tcardinal digit<br>\n",
    "DT\tdeterminer<br>\n",
    "EX\texistential there<br>\n",
    "FW\tforeign word<br>\n",
    "IN\tpreposition/subordinating conjunction<br>\n",
    "JJ\tThis NLTK POS Tag is an adjective (large)<br>\n",
    "JJR\tadjective, comparative (larger)<br>\n",
    "JJS\tadjective, superlative (largest)<br>\n",
    "LS\tlist market<br>\n",
    "MD\tmodal (could, will)<br>\n",
    "NN\tnoun, singular (cat, tree)<br>\n",
    "NNS\tnoun plural (desks)<br>\n",
    "NNP\tproper noun, singular (sarah)<br>\n",
    "NNPS\tproper noun, plural (indians or americans)<br>\n",
    "PDT\tpredeterminer (all, both, half)<br>\n",
    "POS\tpossessive ending (parent\\ 's)<br>\n",
    "PRP\tpersonal pronoun (hers, herself, him,himself)<br>\n",
    "PRP$\tpossessive pronoun (her, his, mine, my, our ) <br>\n",
    "RB\tadverb (occasionally, swiftly) <br>\n",
    "RBR\tadverb, comparative (greater)<br>\n",
    "RBS\tadverb, superlative (biggest)<br>\n",
    "RP\tparticle (about)<br>\n",
    "TO\tinfinite marker (to)<br>\n",
    "UH\tinterjection (goodbye)<br>\n",
    "VB\tverb (ask)<br>\n",
    "VBG\tverb gerund (judging)<br>\n",
    "VBD\tverb past tense (pleaded)<br>\n",
    "VBN\tverb past participle (reunified)<br>\n",
    "VBP\tverb, present tense not 3rd person singular(wrap)<br>\n",
    "VBZ\tverb, present tense with 3rd person singular (bases)<br>\n",
    "WDT\twh-determiner (that, what)<br>\n",
    "WP\twh- pronoun (who)<br>\n",
    "WRB\twh- adverb (how)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd step --> Removal of punctuations\n",
    "# Text cleaning\n",
    "# remove the Stopwords---> words which have common occurence in englisg lang\n",
    "# stopword will consume extra memory which is not requuired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ebineet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')# language\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords will get removed from usecase to use case.\n",
    "# take the list and remove the stopwords that is necessary as per your requitr,emnt\n",
    "# modify the stopwords list from the requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords from the sentence given in class\n",
    "# take a para, word tokenize it and then remove stopwords from it and\n",
    "# apply POS tag on all the new words and lastly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the para\n",
    "para= \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenizing the para\n",
    "word_token = nltk.word_tokenize(para.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " '(',\n",
       " 'hindi',\n",
       " ':',\n",
       " 'bhārat',\n",
       " ')',\n",
       " ',',\n",
       " 'offici',\n",
       " 'republ',\n",
       " 'india',\n",
       " ',',\n",
       " 'countri',\n",
       " 'south',\n",
       " 'asia',\n",
       " '.',\n",
       " 'it',\n",
       " 'seventh-largest',\n",
       " 'countri',\n",
       " 'area',\n",
       " ',',\n",
       " 'second-most',\n",
       " 'popul',\n",
       " 'countri',\n",
       " ',',\n",
       " 'popul',\n",
       " 'democraci',\n",
       " 'world',\n",
       " '.',\n",
       " 'bound',\n",
       " 'indian',\n",
       " 'ocean',\n",
       " 'south',\n",
       " ',',\n",
       " 'arabian',\n",
       " 'sea',\n",
       " 'southwest',\n",
       " ',',\n",
       " 'bay',\n",
       " 'bengal',\n",
       " 'southeast',\n",
       " ',',\n",
       " 'share',\n",
       " 'land',\n",
       " 'border',\n",
       " 'pakistan',\n",
       " 'west',\n",
       " ';',\n",
       " 'china',\n",
       " ',',\n",
       " 'nepal',\n",
       " ',',\n",
       " 'bhutan',\n",
       " 'north',\n",
       " ';',\n",
       " 'bangladesh',\n",
       " 'myanmar',\n",
       " 'east',\n",
       " '.',\n",
       " 'in',\n",
       " 'indian',\n",
       " 'ocean',\n",
       " ',',\n",
       " 'india',\n",
       " 'vicin',\n",
       " 'sri',\n",
       " 'lanka',\n",
       " 'maldiv',\n",
       " ';',\n",
       " 'andaman',\n",
       " 'nicobar',\n",
       " 'island',\n",
       " 'share',\n",
       " 'maritim',\n",
       " 'border',\n",
       " 'thailand',\n",
       " 'indonesia',\n",
       " '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "\n",
    "for word in word_token:\n",
    "    if word not in stop_words:\n",
    "        clean_data.append(word)\n",
    "        \n",
    "pos = nltk.pos_tag(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('india', 'NN'),\n",
       " ('(', '('),\n",
       " ('hindi', 'NN'),\n",
       " (':', ':'),\n",
       " ('bhārat', 'NN'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('offici', 'JJ'),\n",
       " ('republ', 'NN'),\n",
       " ('india', 'NN'),\n",
       " (',', ','),\n",
       " ('countri', 'NN'),\n",
       " ('south', 'JJ'),\n",
       " ('asia', 'NN'),\n",
       " ('.', '.'),\n",
       " ('seventh-largest', 'JJ'),\n",
       " ('countri', 'JJ'),\n",
       " ('area', 'NN'),\n",
       " (',', ','),\n",
       " ('second-most', 'JJ'),\n",
       " ('popul', 'NN'),\n",
       " ('countri', 'NN'),\n",
       " (',', ','),\n",
       " ('popul', 'NN'),\n",
       " ('democraci', 'NN'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('bound', 'NN'),\n",
       " ('indian', 'JJ'),\n",
       " ('ocean', 'NN'),\n",
       " ('south', 'NN'),\n",
       " (',', ','),\n",
       " ('arabian', 'JJ'),\n",
       " ('sea', 'NN'),\n",
       " ('southwest', 'NN'),\n",
       " (',', ','),\n",
       " ('bay', 'JJ'),\n",
       " ('bengal', 'NN'),\n",
       " ('southeast', 'NN'),\n",
       " (',', ','),\n",
       " ('share', 'NN'),\n",
       " ('land', 'NN'),\n",
       " ('border', 'NN'),\n",
       " ('pakistan', 'NN'),\n",
       " ('west', 'NN'),\n",
       " (';', ':'),\n",
       " ('china', 'NNS'),\n",
       " (',', ','),\n",
       " ('nepal', 'JJ'),\n",
       " (',', ','),\n",
       " ('bhutan', 'JJ'),\n",
       " ('north', 'NN'),\n",
       " (';', ':'),\n",
       " ('bangladesh', 'JJ'),\n",
       " ('myanmar', 'NN'),\n",
       " ('east', 'NN'),\n",
       " ('.', '.'),\n",
       " ('indian', 'JJ'),\n",
       " ('ocean', 'NN'),\n",
       " (',', ','),\n",
       " ('india', 'JJ'),\n",
       " ('vicin', 'NN'),\n",
       " ('sri', 'NN'),\n",
       " ('lanka', 'NN'),\n",
       " ('maldiv', 'NN'),\n",
       " (';', ':'),\n",
       " ('andaman', 'JJ'),\n",
       " ('nicobar', 'NN'),\n",
       " ('island', 'NN'),\n",
       " ('share', 'NN'),\n",
       " ('maritim', 'JJ'),\n",
       " ('border', 'NN'),\n",
       " ('thailand', 'NN'),\n",
       " ('indonesia', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lower case\n",
    "# then tokenize\n",
    "# then remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ef1fb954b576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_token\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "word_token = word_token.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0d2a01e4458b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclean_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_token\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mclean_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "clean_data = []\n",
    "\n",
    "for word in word_token.lower():\n",
    "    if word not in stop_words:\n",
    "        clean_data.append(word)\n",
    "        \n",
    "pos = nltk.pos_tag(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the punctaution\n",
    "\n",
    "import string\n",
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question!\n",
    "#WAP text will convert to lower wode tokenzise remove the stopwords \n",
    "#and punctuation and convert again to para and retuen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "para1 = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenizing the para\n",
    "word_token = nltk.word_tokenize(para1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "\n",
    "for word in word_token:\n",
    "    if word not in stop_words:\n",
    "        clean_data.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punct = string.punctuation\n",
    "\n",
    "data = []\n",
    "\n",
    "for word in clean_data:\n",
    "    if word not in punct:\n",
    "        data.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'india hindi bhārat officially republic india country south asia seventh-largest country area second-most populous country populous democracy world bounded indian ocean south arabian sea southwest bay bengal southeast shares land borders pakistan west china nepal bhutan north bangladesh myanmar east indian ocean india vicinity sri lanka maldives andaman nicobar islands share maritime border thailand indonesia'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer!\n",
    "\n",
    "### using optimized way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "\n",
    "for word in word_token.lower():\n",
    "    if word not in punct:\n",
    "        if word not in stop_words:\n",
    "            clean_data.append(word)\n",
    "pos = nltk.pos_tag(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer!\n",
    "### using OOP concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class Cleaning:\n",
    "    \n",
    "    def__init__(self): # default constructor\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('averaged_perceptron_tagger')\n",
    "        nltk.download('stopwords')\n",
    "        self.punct= string.punctuation\n",
    "        \n",
    "    def preprocesssing(slef,para):\n",
    "        \"\"\"\n",
    "        function which \n",
    "        lowers, \n",
    "        word tokenize, \n",
    "        remove stopwords, \n",
    "        remove punctuation\n",
    "        \n",
    "        parameters:\n",
    "        --------------------------------------\n",
    "        para(str)--- unclean data\n",
    "        \n",
    "        returns(str) --- clean data\n",
    "        \"\"\"\n",
    "        \n",
    "        clean_data = []\n",
    "        for word in word_token.lower():\n",
    "            if word not in punct:\n",
    "                if word not in stop_words:\n",
    "                    clean_data.append(word)\n",
    "        return \" \".join(clean_data)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class Cleaning:\n",
    "    \n",
    "    def __init__(self):\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('averaged_perceptron_tagger')\n",
    "        nltk.download('stopwords')\n",
    "        self.punct = string.punctuation\n",
    "        self.stop_words = stopwords.words('english')\n",
    "    \n",
    "    def preprocessing(self , para):\n",
    "        \"\"\"\n",
    "        function which \n",
    "        1. lowers\n",
    "        2. work token\n",
    "        3. remove stopwords\n",
    "        4. remove the punctuation\n",
    "        \n",
    "        parameters\n",
    "        ---------------------------\n",
    "        para(str) - unclean data\n",
    "        \n",
    "        retunrs\n",
    "        --------------------------\n",
    "        returns (str) -- clean data\n",
    "        \"\"\"\n",
    "        \n",
    "        clean_data = []\n",
    "        for word in nltk.word_tokenize(para.lower()):\n",
    "\n",
    "            if word not in self.punct:\n",
    "                if word not in self.stop_words:\n",
    "                    clean_data.append(word)\n",
    "        \n",
    "        return \" \".join(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Cleaning()\n",
    "pre.preprocessing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming/ Lementization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "print('porter stemmer')\n",
    "print(porter.stem('hobby'))\n",
    "print(porter.stem('hobbies'))\n",
    "print(porter.stem('computer'))\n",
    "print(porter.stem('computation'))\n",
    "print('---------------------------------')\n",
    "print('lancaster stemmer')\n",
    "print(lancaster.stem('hobby'))\n",
    "print(lancaster.stem('hobbies'))\n",
    "print(lancaster.stem('computer'))\n",
    "print(lancaster.stem('computation'))\n",
    "print('---------------------------------')\n",
    "print('snowball stemmer')\n",
    "print(snowball.stem('hobby'))\n",
    "print(snowball.stem('hobbies'))\n",
    "print(snowball.stem('computer'))\n",
    "print(snowball.stem('computation'))\n",
    "print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ebineet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmetization\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "run\n",
      "ran\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('running'))\n",
    "print(lemma.lemmatize('runs'))\n",
    "print(lemma.lemmatize('ran'))\n",
    "\n",
    "# convert all to verb. POS as verb. root words is of Verbs not noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "# convert all to verb. POS as verb. root words is of Verbs not noun.\n",
    "print(lemma.lemmatize('running', 'v'))\n",
    "print(lemma.lemmatize('runs', 'v'))\n",
    "print(lemma.lemmatize('ran', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
